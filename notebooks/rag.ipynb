{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using https://learnbybuilding.ai/tutorials/rag-from-scratch as a tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Baby's First RAG \"\"\"\n",
    "\n",
    "corpus_of_documents = [\n",
    "    \"Take a leisurely walk in the park and enjoy the fresh air.\",\n",
    "    \"Visit a local museum and discover something new.\",\n",
    "    \"Attend a live music concert and feel the rhythm.\",\n",
    "    \"Go for a hike and admire the natural scenery.\",\n",
    "    \"Have a picnic with friends and share some laughs.\",\n",
    "    \"Explore a new cuisine by dining at an ethnic restaurant.\",\n",
    "    \"Take a yoga class and stretch your body and mind.\",\n",
    "    \"Join a local sports league and enjoy some friendly competition.\",\n",
    "    \"Attend a workshop or lecture on a topic you're interested in.\",\n",
    "    \"Visit an amusement park and ride the roller coasters.\"\n",
    "]\n",
    "\n",
    "def jaccard_similarity(query, document) -> float:\n",
    "    \"\"\" Pre-processes plain strings into a set to perform comparisons.\n",
    "\n",
    "    Args:\n",
    "        query (_type_): _description_\n",
    "        document (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        float: _description_\n",
    "    \"\"\"\n",
    "    query = query.lower().split(\" \")\n",
    "    document = document.lower().split(\" \")\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "def return_response(query, corpus) -> str:\n",
    "    \"\"\" Selects the best document to return to the user\n",
    "\n",
    "    Args:\n",
    "        query (_type_): _description_\n",
    "        corpus (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        str: _description_\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    for doc in corpus:\n",
    "        similarity = jaccard_similarity(user_input, doc)\n",
    "        similarities.append(similarity)\n",
    "    return corpus_of_documents[similarities.index(max(similarities))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"What is a leisure activity that you like?\"\n",
    "user_input = \"I like to be with friends\"\n",
    "return_response(user_input, corpus_of_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import ollama\n",
    "ollama.pull('mistral')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_input = \"I like to see my friends\"\n",
    "relevant_document = return_response(user_input, corpus_of_documents)\n",
    "full_response = []\n",
    "# https://github.com/jmorganca/ollama/blob/main/docs/api.md\n",
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information.\n",
    "This is the recommended activity: {relevant_document}\n",
    "The user input is: {user_input}\n",
    "Compile a recommendation to the user based on the recommended activity and the user input.\n",
    "\"\"\"\n",
    "\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "data = {\n",
    "    \"model\": \"mistral:latest\",\n",
    "    \"prompt\": prompt.format(user_input=user_input, relevant_document=relevant_document)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    count = 0\n",
    "    for line in response.iter_lines():\n",
    "        # filter out keep-alive new lines\n",
    "        # count += 1\n",
    "        # if count % 5== 0:\n",
    "        #     print(decoded_line['response']) # print every fifth token\n",
    "        if line:\n",
    "            decoded_line = json.loads(line.decode('utf-8'))\n",
    "            if 'response' in decoded_line:\n",
    "                full_response.append(decoded_line['response'])\n",
    "            else:\n",
    "                print(\"Warning: 'response' key not found in the data:\", decoded_line)\n",
    "finally:\n",
    "    response.close()\n",
    "print(''.join(full_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I don't like to hike\"\n",
    "relevant_document = return_response(user_input, corpus_of_documents)\n",
    "# https://github.com/jmorganca/ollama/blob/main/docs/api.md\n",
    "full_response = []\n",
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information.\n",
    "This is the recommended activity: {relevant_document}\n",
    "The user input is: {user_input}\n",
    "Compile a recommendation to the user based on the recommended activity and the user input.\n",
    "\"\"\"\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "data = {\n",
    "    \"model\": \"mistral:latest\",\n",
    "    \"prompt\": prompt.format(user_input=user_input, relevant_document=relevant_document)\n",
    "}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "try:\n",
    "    for line in response.iter_lines():\n",
    "        # filter out keep-alive new lines\n",
    "        if line:\n",
    "            decoded_line = json.loads(line.decode('utf-8'))\n",
    "            # print(decoded_line['response'])  # uncomment to results, token by token\n",
    "            full_response.append(decoded_line['response'])\n",
    "finally:\n",
    "    response.close()\n",
    "print(''.join(full_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ends the tutorial at https://learnbybuilding.ai/tutorials/rag-from-scratch \n",
    "Now to go into https://learnbybuilding.ai/tutorials/rag-from-scratch-part-2-semantics-and-cosine-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_of_documents = [\n",
    "    \"Take a leisurely walk in the park and enjoy the fresh air.\",\n",
    "    \"Visit a local museum and discover something new.\",\n",
    "    \"Attend a live music concert and feel the rhythm.\",\n",
    "    \"Go for a hike and admire the natural scenery.\",\n",
    "    \"Have a picnic with friends and share some laughs.\",\n",
    "    \"Explore a new cuisine by dining at an ethnic restaurant.\",\n",
    "    \"Take a yoga class and stretch your body and mind.\",\n",
    "    \"Join a local sports league and enjoy some friendly competition.\",\n",
    "    \"Attend a workshop or lecture on a topic you're interested in.\",\n",
    "    \"Visit an amusement park and ride the roller coasters.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "doc_embeddings = model.encode(corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "query = \"What's the best activity to do with friends?\"\n",
    "query_embedding = model.encode([query])\n",
    "similarities = cosine_similarity(query_embedding, doc_embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed = list(enumerate(similarities[0]))\n",
    "sorted_index = sorted(indexed, key=lambda x: x[1], reverse=True)\n",
    "print(sorted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_documents = []\n",
    "for value, score in sorted_index:\n",
    "    formatted_score = \"{:.2f}\".format(score)\n",
    "    print(f\"{formatted_score} => {corpus_of_documents[value]}\")\n",
    "    if score > 0.3:\n",
    "        recommended_documents.append(corpus_of_documents[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information.\n",
    "These are potential activities:\n",
    "{recommended_activities}\n",
    "The user's query is: {user_input}\n",
    "Provide the user with 2 recommended activities based on their query.\n",
    "\"\"\"\n",
    "recommended_activities = \"\\n\".join(recommended_documents)\n",
    "user_input = \"I like to spend time with my friends\"\n",
    "full_prompt = prompt.format(user_input=user_input, recommended_activities=recommended_activities)\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "data = {\n",
    "    \"model\": \"mistral:latest\",\n",
    "    \"prompt\": full_prompt\n",
    "}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "full_response=[]\n",
    "try:\n",
    "    count = 0\n",
    "    for line in response.iter_lines():\n",
    "        #filter out keep-alive new lines\n",
    "        # count += 1\n",
    "        # if count % 5== 0:\n",
    "        #     print(decoded_line['response']) # print every fifth token\n",
    "        if line:\n",
    "            decoded_line = json.loads(line.decode('utf-8'))\n",
    "            \n",
    "            full_response.append(decoded_line['response'])\n",
    "finally:\n",
    "    response.close()\n",
    "print(''.join(full_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.ingest.connector.local import SimpleLocalConfig\n",
    "from unstructured.ingest.connector.weaviate import (\n",
    "    SimpleWeaviateConfig,\n",
    "    WeaviateAccessConfig,\n",
    "    WeaviateWriteConfig,\n",
    ")\n",
    "from unstructured.ingest.interfaces import (\n",
    "    ChunkingConfig,\n",
    "    EmbeddingConfig,\n",
    "    PartitionConfig,\n",
    "    ProcessorConfig,\n",
    "    ReadConfig,\n",
    ")\n",
    "from unstructured.ingest.runner import LocalRunner\n",
    "from unstructured.ingest.runner.writers.base_writer import Writer\n",
    "from unstructured.ingest.runner.writers.weaviate import (\n",
    "    WeaviateWriter,\n",
    ")\n",
    "\n",
    "\n",
    "def get_writer() -> Writer:\n",
    "    return WeaviateWriter(\n",
    "        connector_config=SimpleWeaviateConfig(\n",
    "            access_config=WeaviateAccessConfig(),\n",
    "            host_url=\"http://localhost:8080\",\n",
    "            class_name=\"elements\",\n",
    "        ),\n",
    "        write_config=WeaviateWriteConfig(),\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    writer = get_writer()\n",
    "    runner = LocalRunner(\n",
    "        processor_config=ProcessorConfig(\n",
    "            verbose=True,\n",
    "            output_dir=\"docs\",\n",
    "            num_processes=2,\n",
    "        ),\n",
    "        connector_config=SimpleLocalConfig(\n",
    "            input_path=\"docs/Player_s Handbook.pdf\",\n",
    "        ),\n",
    "        read_config=ReadConfig(),\n",
    "        partition_config=PartitionConfig(),\n",
    "        chunking_config=ChunkingConfig(chunk_elements=True),\n",
    "        embedding_config=EmbeddingConfig(\n",
    "            provider=\"langchain-huggingface\",\n",
    "        ),\n",
    "        writer=writer,\n",
    "        writer_kwargs={},\n",
    "    )\n",
    "    runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to isolate embedding before putting into Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../requirements.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"unstructured[local-inference]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.documents.elements import Title, NarrativeText, Text\n",
    "from unstructured.chunking.basic import chunk_elements\n",
    "from typing import List\n",
    "import os\n",
    "import weaviate\n",
    "from weaviate.util import generate_uuid5\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "../setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "ollama.pull(\"mxbai-embed-large:v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import convert_to_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this: https://docs.twilix.io/tutorials/talk-to-pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"../docs/NIST.SP.800-171r2.pdf\"\n",
    "\n",
    "def process_pdf(file_path: str):\n",
    "    # partition the pdf\n",
    "    elements = partition_pdf(filename=file_path, strategy=\"fast\")\n",
    "    # convert elements into strings\n",
    "    texts = [str(el) for el in elements]\n",
    "    return texts\n",
    "\n",
    "docs = process_pdf(FILE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
