{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using https://learnbybuilding.ai/tutorials/rag-from-scratch as a tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Baby's First RAG \"\"\"\n",
    "\n",
    "corpus_of_documents = [\n",
    "    \"Take a leisurely walk in the park and enjoy the fresh air.\",\n",
    "    \"Visit a local museum and discover something new.\",\n",
    "    \"Attend a live music concert and feel the rhythm.\",\n",
    "    \"Go for a hike and admire the natural scenery.\",\n",
    "    \"Have a picnic with friends and share some laughs.\",\n",
    "    \"Explore a new cuisine by dining at an ethnic restaurant.\",\n",
    "    \"Take a yoga class and stretch your body and mind.\",\n",
    "    \"Join a local sports league and enjoy some friendly competition.\",\n",
    "    \"Attend a workshop or lecture on a topic you're interested in.\",\n",
    "    \"Visit an amusement park and ride the roller coasters.\"\n",
    "]\n",
    "\n",
    "def jaccard_similarity(query, document) -> float:\n",
    "    \"\"\" Pre-processes plain strings into a set to perform comparisons.\n",
    "\n",
    "    Args:\n",
    "        query (_type_): _description_\n",
    "        document (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        float: _description_\n",
    "    \"\"\"\n",
    "    query = query.lower().split(\" \")\n",
    "    document = document.lower().split(\" \")\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "def return_response(query, corpus) -> str:\n",
    "    \"\"\" Selects the best document to return to the user\n",
    "\n",
    "    Args:\n",
    "        query (_type_): _description_\n",
    "        corpus (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        str: _description_\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    for doc in corpus:\n",
    "        similarity = jaccard_similarity(user_input, doc)\n",
    "        similarities.append(similarity)\n",
    "    return corpus_of_documents[similarities.index(max(similarities))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Have a picnic with friends and share some laughs.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"What is a leisure activity that you like?\"\n",
    "user_input = \"I like to be with friends\"\n",
    "return_response(user_input, corpus_of_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import ollama\n",
    "ollama.pull('mistral')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_input = \"I like to see my friends\"\n",
    "relevant_document = return_response(user_input, corpus_of_documents)\n",
    "full_response = []\n",
    "# https://github.com/jmorganca/ollama/blob/main/docs/api.md\n",
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information.\n",
    "This is the recommended activity: {relevant_document}\n",
    "The user input is: {user_input}\n",
    "Compile a recommendation to the user based on the recommended activity and the user input.\n",
    "\"\"\"\n",
    "\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "data = {\n",
    "    \"model\": \"mistral:latest\",\n",
    "    \"prompt\": prompt.format(user_input=user_input, relevant_document=relevant_document)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Plan a picnic with your friends for some quality time and shared laughter.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    count = 0\n",
    "    for line in response.iter_lines():\n",
    "        # filter out keep-alive new lines\n",
    "        # count += 1\n",
    "        # if count % 5== 0:\n",
    "        #     print(decoded_line['response']) # print every fifth token\n",
    "        if line:\n",
    "            decoded_line = json.loads(line.decode('utf-8'))\n",
    "            if 'response' in decoded_line:\n",
    "                full_response.append(decoded_line['response'])\n",
    "            else:\n",
    "                print(\"Warning: 'response' key not found in the data:\", decoded_line)\n",
    "finally:\n",
    "    response.close()\n",
    "print(''.join(full_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " If you don't like hiking, consider trying other outdoor activities such as having a picnic in a park or going for a leisurely walk instead.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I don't like to hike\"\n",
    "relevant_document = return_response(user_input, corpus_of_documents)\n",
    "# https://github.com/jmorganca/ollama/blob/main/docs/api.md\n",
    "full_response = []\n",
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information.\n",
    "This is the recommended activity: {relevant_document}\n",
    "The user input is: {user_input}\n",
    "Compile a recommendation to the user based on the recommended activity and the user input.\n",
    "\"\"\"\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "data = {\n",
    "    \"model\": \"mistral:latest\",\n",
    "    \"prompt\": prompt.format(user_input=user_input, relevant_document=relevant_document)\n",
    "}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "try:\n",
    "    for line in response.iter_lines():\n",
    "        # filter out keep-alive new lines\n",
    "        if line:\n",
    "            decoded_line = json.loads(line.decode('utf-8'))\n",
    "            # print(decoded_line['response'])  # uncomment to results, token by token\n",
    "            full_response.append(decoded_line['response'])\n",
    "finally:\n",
    "    response.close()\n",
    "print(''.join(full_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ends the tutorial at https://learnbybuilding.ai/tutorials/rag-from-scratch \n",
    "Now to go into https://learnbybuilding.ai/tutorials/rag-from-scratch-part-2-semantics-and-cosine-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_of_documents = [\n",
    "    \"Take a leisurely walk in the park and enjoy the fresh air.\",\n",
    "    \"Visit a local museum and discover something new.\",\n",
    "    \"Attend a live music concert and feel the rhythm.\",\n",
    "    \"Go for a hike and admire the natural scenery.\",\n",
    "    \"Have a picnic with friends and share some laughs.\",\n",
    "    \"Explore a new cuisine by dining at an ethnic restaurant.\",\n",
    "    \"Take a yoga class and stretch your body and mind.\",\n",
    "    \"Join a local sports league and enjoy some friendly competition.\",\n",
    "    \"Attend a workshop or lecture on a topic you're interested in.\",\n",
    "    \"Visit an amusement park and ride the roller coasters.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb9f12eb46b4c70b84ae50141dfed74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1289f5e9c64626a2d126343a0d0a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a310d19576bd48b7b6039e2342740ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6f40f10e8d44cc83fec7dbbfcd99ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b42c140a55f486fac209dd54a3bc828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db98c4fcfe674778b0502491477a1065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6390b56e680d4a94a0f5eda3d9d7bee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f6d805ae084c478ac7c8940366076e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3b144428da42e78cab5b813f19c1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22e8ead0a4b461b8d717427e00860de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51abfb9fee24ef198e01cd24e97d599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaminaduck/code/ai-holodeck/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "doc_embeddings = model.encode(corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07121074 -0.01087999  0.11746483 ...  0.01414925 -0.13175759\n",
      "  -0.00402594]\n",
      " [ 0.0488153  -0.03166638  0.07468719 ... -0.06278274 -0.11120293\n",
      "   0.03045148]\n",
      " [ 0.05019969 -0.09127744  0.08517752 ...  0.01286448 -0.07415236\n",
      "  -0.06140349]\n",
      " ...\n",
      " [ 0.05416269 -0.03030901  0.02475945 ... -0.01272298 -0.06512286\n",
      "   0.05848261]\n",
      " [-0.00401893 -0.04562391 -0.00900756 ...  0.0393975  -0.12731639\n",
      "   0.05255732]\n",
      " [ 0.05046043  0.01430451  0.08787955 ... -0.01778722 -0.0524641\n",
      "  -0.02887328]]\n"
     ]
    }
   ],
   "source": [
    "print(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40328795 0.36643532 0.3439691  0.3713997  0.6033779  0.27722937\n",
      "  0.20104659 0.27300793 0.24499053 0.47120166]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "query = \"What's the best activity to do with friends?\"\n",
    "query_embedding = model.encode([query])\n",
    "similarities = cosine_similarity(query_embedding, doc_embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 0.6033779), (9, 0.47120166), (0, 0.40328795), (3, 0.3713997), (1, 0.36643532), (2, 0.3439691), (5, 0.27722937), (7, 0.27300793), (8, 0.24499053), (6, 0.20104659)]\n"
     ]
    }
   ],
   "source": [
    "indexed = list(enumerate(similarities[0]))\n",
    "sorted_index = sorted(indexed, key=lambda x: x[1], reverse=True)\n",
    "print(sorted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60 => Have a picnic with friends and share some laughs.\n",
      "0.47 => Visit an amusement park and ride the roller coasters.\n",
      "0.40 => Take a leisurely walk in the park and enjoy the fresh air.\n",
      "0.37 => Go for a hike and admire the natural scenery.\n",
      "0.37 => Visit a local museum and discover something new.\n",
      "0.34 => Attend a live music concert and feel the rhythm.\n",
      "0.28 => Explore a new cuisine by dining at an ethnic restaurant.\n",
      "0.27 => Join a local sports league and enjoy some friendly competition.\n",
      "0.24 => Attend a workshop or lecture on a topic you're interested in.\n",
      "0.20 => Take a yoga class and stretch your body and mind.\n"
     ]
    }
   ],
   "source": [
    "recommended_documents = []\n",
    "for value, score in sorted_index:\n",
    "    formatted_score = \"{:.2f}\".format(score)\n",
    "    print(f\"{formatted_score} => {corpus_of_documents[value]}\")\n",
    "    if score > 0.3:\n",
    "        recommended_documents.append(corpus_of_documents[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Have a picnic with friends.\n",
      "Visit an amusement park together.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information.\n",
    "These are potential activities:\n",
    "{recommended_activities}\n",
    "The user's query is: {user_input}\n",
    "Provide the user with 2 recommended activities based on their query.\n",
    "\"\"\"\n",
    "recommended_activities = \"\\n\".join(recommended_documents)\n",
    "user_input = \"I like to spend time with my friends\"\n",
    "full_prompt = prompt.format(user_input=user_input, recommended_activities=recommended_activities)\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "data = {\n",
    "    \"model\": \"mistral:latest\",\n",
    "    \"prompt\": full_prompt\n",
    "}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "full_response=[]\n",
    "try:\n",
    "    count = 0\n",
    "    for line in response.iter_lines():\n",
    "        #filter out keep-alive new lines\n",
    "        # count += 1\n",
    "        # if count % 5== 0:\n",
    "        #     print(decoded_line['response']) # print every fifth token\n",
    "        if line:\n",
    "            decoded_line = json.loads(line.decode('utf-8'))\n",
    "            \n",
    "            full_response.append(decoded_line['response'])\n",
    "finally:\n",
    "    response.close()\n",
    "print(''.join(full_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 19:50:21,058 MainProcess INFO     running pipeline: DocFactory -> Reader -> Partitioner -> Chunker -> Embedder -> Writer -> Copier with config: {\"reprocess\": false, \"verbose\": true, \"work_dir\": \"/home/kaminaduck/.cache/unstructured/ingest/pipeline\", \"output_dir\": \"local-output-to-weaviate\", \"num_processes\": 2, \"raise_on_error\": false}\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-04-16 19:50:21,071 MainProcess INFO     Running doc factory to generate ingest docs. Source connector: {\"processor_config\": {\"reprocess\": false, \"verbose\": true, \"work_dir\": \"/home/kaminaduck/.cache/unstructured/ingest/pipeline\", \"output_dir\": \"local-output-to-weaviate\", \"num_processes\": 2, \"raise_on_error\": false}, \"read_config\": {\"download_dir\": \"\", \"re_download\": false, \"preserve_downloads\": false, \"download_only\": false, \"max_docs\": null}, \"connector_config\": {\"input_path\": \"docs/Player_s Handbook.pdf\", \"recursive\": false, \"file_glob\": null}}\n",
      "2024-04-16 19:50:21,074 MainProcess INFO     no docs found to process\n"
     ]
    }
   ],
   "source": [
    "from unstructured.ingest.connector.local import SimpleLocalConfig\n",
    "from unstructured.ingest.connector.weaviate import (\n",
    "    SimpleWeaviateConfig,\n",
    "    WeaviateAccessConfig,\n",
    "    WeaviateWriteConfig,\n",
    ")\n",
    "from unstructured.ingest.interfaces import (\n",
    "    ChunkingConfig,\n",
    "    EmbeddingConfig,\n",
    "    PartitionConfig,\n",
    "    ProcessorConfig,\n",
    "    ReadConfig,\n",
    ")\n",
    "from unstructured.ingest.runner import LocalRunner\n",
    "from unstructured.ingest.runner.writers.base_writer import Writer\n",
    "from unstructured.ingest.runner.writers.weaviate import (\n",
    "    WeaviateWriter,\n",
    ")\n",
    "\n",
    "\n",
    "def get_writer() -> Writer:\n",
    "    return WeaviateWriter(\n",
    "        connector_config=SimpleWeaviateConfig(\n",
    "            access_config=WeaviateAccessConfig(),\n",
    "            host_url=\"http://localhost:8080\",\n",
    "            class_name=\"elements\",\n",
    "        ),\n",
    "        write_config=WeaviateWriteConfig(),\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    writer = get_writer()\n",
    "    runner = LocalRunner(\n",
    "        processor_config=ProcessorConfig(\n",
    "            verbose=True,\n",
    "            output_dir=\"docs\",\n",
    "            num_processes=2,\n",
    "        ),\n",
    "        connector_config=SimpleLocalConfig(\n",
    "            input_path=\"docs/Player_s Handbook.pdf\",\n",
    "        ),\n",
    "        read_config=ReadConfig(),\n",
    "        partition_config=PartitionConfig(),\n",
    "        chunking_config=ChunkingConfig(chunk_elements=True),\n",
    "        embedding_config=EmbeddingConfig(\n",
    "            provider=\"langchain-huggingface\",\n",
    "        ),\n",
    "        writer=writer,\n",
    "        writer_kwargs={},\n",
    "    )\n",
    "    runner.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
